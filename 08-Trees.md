
# 07-Trees

* model selection -- regularization, PCA and PCR
* decision tree basics
* bagging and random forests

## Reading (for Thursday)

* ISLR2 -- Chapter 8, Section 8.1: The Basics of Decision Trees

## Notebooks

* [07-logreg-iris-regularization.ipynb](https://colab.research.google.com/drive/12Vs332xNtq7s2aIZvcof221uVo1G6DQL)
* [07-principal components](https://colab.research.google.com/drive/1KPXIhCoPorVjtXIYLGt7m-ZAcHM8FK7X)
* [08-hitters-eda-exercises](https://colab.research.google.com/drive/1WTfGzLTF6PfWS1GIgslwHfwQZvPp_uDJ)
* [scratch-notebook](https://colab.research.google.com/drive/1H4sj-XdST_PqBXQTrkutsamSFrOs2wNG)
* [poll everywhere](https://pollev.com/pbogden)

## In-class exercises: Iris regularization

* [exercises.md](exercises.md)

## Dimensionality reduction

* [07-principal-components.ipynb](https://colab.research.google.com/drive/1Xc5SNhD9NY-4IGE-mGdPu8mdpPTxHIIf?usp=sharing)
* Can be put into a pipeline, just as we saw with the scikit-learn scandard scaler
* When we do so, we get PCR (Principal Component Regression) as discussion in Section 6.3.1 in ISLR2

## In-class exercises: Hitters PCR

* [exercises.md](exercises.md)

## In-class exercises: Hitters Tree

* [exercises.md](exercises.md)
